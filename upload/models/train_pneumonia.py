"""
èƒ¸éƒ¨Xå…‰è‚ºç‚è¯†åˆ«æ¨¡å‹è®­ç»ƒ
æ•°æ®é›†ï¼šChest X-Ray Images (Pneumonia)
Kaggle: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
import os

print("=" * 60)
print("ğŸ« èƒ¸éƒ¨Xå…‰è‚ºç‚è¯†åˆ«æ¨¡å‹è®­ç»ƒç¨‹åº")
print("=" * 60)

# ========== 1. é…ç½®å‚æ•° ==========
print("\n[1/8] é…ç½®è®­ç»ƒå‚æ•°...")

BASE_DIR = 'C:/MedicalAI'
DATA_DIR = f'{BASE_DIR}/datasets/chest_xray'
MODEL_DIR = f'{BASE_DIR}/models'
LABELS_DIR = f'{BASE_DIR}/labels'

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
os.makedirs(MODEL_DIR, exist_ok=True)
os.makedirs(LABELS_DIR, exist_ok=True)

# æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å­˜åœ¨
if not os.path.exists(DATA_DIR):
    print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®é›† {DATA_DIR}")
    print("è¯·ç¡®ä¿å·²ä¸‹è½½å¹¶è§£å‹Chest X-Rayæ•°æ®é›†åˆ°æŒ‡å®šä½ç½®")
    print("ä¸‹è½½åœ°å€: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia")
    exit(1)

# è®­ç»ƒå‚æ•°
IMG_SIZE = 224
BATCH_SIZE = 32
EPOCHS = 20
LEARNING_RATE = 0.001
MODEL_NAME = 'pneumonia'
CLASS_NAMES = ['NORMAL', 'PNEUMONIA']
CLASS_NAMES_CN = ['æ­£å¸¸', 'è‚ºç‚']

print(f"  æ•°æ®è·¯å¾„: {DATA_DIR}")
print(f"  å›¾åƒå¤§å°: {IMG_SIZE}x{IMG_SIZE}")
print(f"  æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
print(f"  è®­ç»ƒè½®æ•°: {EPOCHS}")
print(f"  æ¨¡å‹åç§°: {MODEL_NAME}")

# ========== 2. åŠ è½½æ•°æ® ==========
print("\n[2/8] åŠ è½½æ•°æ®...")

# è®­ç»ƒé›†
train_ds = keras.preprocessing.image_dataset_from_directory(
    f'{DATA_DIR}/train',
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    label_mode='binary',
    color_mode='grayscale',
    seed=42
)

# æµ‹è¯•é›†
test_ds = keras.preprocessing.image_dataset_from_directory(
    f'{DATA_DIR}/test',
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    label_mode='binary',
    color_mode='grayscale',
    seed=42
)

print(f"  ç±»åˆ«: {train_ds.class_names}")
print(f"  è®­ç»ƒæ‰¹æ¬¡: {len(train_ds)}")
print(f"  æµ‹è¯•æ‰¹æ¬¡: {len(test_ds)}")

# ========== 3. æ•°æ®é¢„å¤„ç† ==========
print("\n[3/8] é…ç½®æ•°æ®å¤„ç†...")

def preprocess(image, label):
    image = tf.cast(image, tf.float32) / 255.0
    return image, label

def augment(image, label):
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_brightness(image, 0.1)
    image = tf.image.random_contrast(image, 0.9, 1.1)
    return image, label

train_ds = train_ds.map(preprocess).map(augment)
test_ds = test_ds.map(preprocess)

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)

print("  âœ“ æ•°æ®å¢å¼ºå·²é…ç½®")
print("  âœ“ æ•°æ®ç®¡é“å·²ä¼˜åŒ–")

# ========== 4. æ„å»ºæ¨¡å‹ ==========
print("\n[4/8] æ„å»ºæ¨¡å‹...")

base_model = keras.applications.MobileNetV2(
    input_shape=(IMG_SIZE, IMG_SIZE, 3),
    include_top=False,
    weights='imagenet'
)
base_model.trainable = False

model = keras.Sequential([
    layers.Input(shape=(IMG_SIZE, IMG_SIZE, 1)),
    layers.Conv2D(3, (1, 1), padding='same'),
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Dense(256, activation='relu'),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(1, activation='sigmoid')
])

print(f"  æ¨¡å‹å±‚æ•°: {len(model.layers)}")
print(f"  å¯è®­ç»ƒå‚æ•°: {model.count_params():,}")

# ========== 5. ç¼–è¯‘æ¨¡å‹ ==========
print("\n[5/8] ç¼–è¯‘æ¨¡å‹...")

model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    loss='binary_crossentropy',
    metrics=[
        'accuracy',
        keras.metrics.Precision(name='precision'),
        keras.metrics.Recall(name='recall'),
        keras.metrics.AUC(name='auc')
    ]
)

print("  âœ“ ä¼˜åŒ–å™¨: Adam")
print("  âœ“ æŸå¤±å‡½æ•°: Binary Crossentropy")
print("  âœ“ è¯„ä¼°æŒ‡æ ‡: Accuracy, Precision, Recall, AUC")

# ========== 6. è®­ç»ƒæ¨¡å‹ ==========
print("\n[6/8] å¼€å§‹è®­ç»ƒ...\n")

callbacks = [
    keras.callbacks.EarlyStopping(
        monitor='val_accuracy',
        patience=5,
        restore_best_weights=True,
        verbose=1
    ),
    keras.callbacks.ModelCheckpoint(
        f'{MODEL_DIR}/{MODEL_NAME}_best.h5',
        monitor='val_accuracy',
        save_best_only=True,
        verbose=1
    ),
    keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=3,
        min_lr=1e-7,
        verbose=1
    )
]

history = model.fit(
    train_ds,
    validation_data=test_ds,
    epochs=EPOCHS,
    callbacks=callbacks,
    verbose=1
)

# ========== 7. è¯„ä¼°å’Œä¿å­˜ ==========
print("\n[7/8] è¯„ä¼°æ¨¡å‹...")

results = model.evaluate(test_ds, verbose=0)

print("\n" + "=" * 60)
print(f"ğŸ« {MODEL_NAME.upper()} è®­ç»ƒå®Œæˆï¼æœ€ç»ˆæµ‹è¯•ç»“æœ:")
print("=" * 60)
print(f"  æŸå¤±å€¼:   {results[0]:.4f}")
print(f"  å‡†ç¡®ç‡:   {results[1]*100:.2f}%")
print(f"  ç²¾ç¡®ç‡:   {results[2]*100:.2f}%")
print(f"  å¬å›ç‡:   {results[3]*100:.2f}%")
print(f"  AUC:      {results[4]:.4f}")
print("=" * 60)

# ä¿å­˜æ¨¡å‹
model_path = f'{MODEL_DIR}/{MODEL_NAME}_model.h5'
model.save(model_path)
print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜: {model_path}")

# ä¿å­˜æ ‡ç­¾
labels_path = f'{LABELS_DIR}/{MODEL_NAME}_labels.txt'
with open(labels_path, 'w', encoding='utf-8') as f:
    for en, cn in zip(CLASS_NAMES, CLASS_NAMES_CN):
        f.write(f"{en}|{cn}\n")
print(f"âœ… æ ‡ç­¾å·²ä¿å­˜: {labels_path}")

# ========== 8. ç»˜åˆ¶è®­ç»ƒæ›²çº¿ ==========
print("\n[8/8] ç»˜åˆ¶è®­ç»ƒæ›²çº¿...")

plt.style.use('seaborn-v0_8-darkgrid')
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle(f'{MODEL_NAME.upper()} æ¨¡å‹è®­ç»ƒæ›²çº¿', fontsize=16, fontweight='bold')

axes[0, 0].plot(history.history['accuracy'], 'b-', label='è®­ç»ƒ', linewidth=2)
axes[0, 0].plot(history.history['val_accuracy'], 'r-', label='éªŒè¯', linewidth=2)
axes[0, 0].set_title('å‡†ç¡®ç‡', fontsize=14)
axes[0, 0].set_xlabel('Epoch')
axes[0, 0].set_ylabel('Accuracy')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

axes[0, 1].plot(history.history['loss'], 'b-', label='è®­ç»ƒ', linewidth=2)
axes[0, 1].plot(history.history['val_loss'], 'r-', label='éªŒè¯', linewidth=2)
axes[0, 1].set_title('æŸå¤±å€¼', fontsize=14)
axes[0, 1].set_xlabel('Epoch')
axes[0, 1].set_ylabel('Loss')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

axes[1, 0].plot(history.history['precision'], 'g-', label='è®­ç»ƒ', linewidth=2)
axes[1, 0].plot(history.history['val_precision'], 'orange', label='éªŒè¯', linewidth=2)
axes[1, 0].set_title('ç²¾ç¡®ç‡', fontsize=14)
axes[1, 0].set_xlabel('Epoch')
axes[1, 0].set_ylabel('Precision')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

axes[1, 1].plot(history.history['recall'], 'purple', label='è®­ç»ƒ', linewidth=2)
axes[1, 1].plot(history.history['val_recall'], 'brown', label='éªŒè¯', linewidth=2)
axes[1, 1].set_title('å¬å›ç‡', fontsize=14)
axes[1, 1].set_xlabel('Epoch')
axes[1, 1].set_ylabel('Recall')
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(f'{MODEL_DIR}/{MODEL_NAME}_training.png', dpi=150, bbox_inches='tight')
print(f"âœ… è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {MODEL_NAME}_training.png")

print("\n" + "=" * 60)
print(f"ğŸ‰ {MODEL_NAME.upper()} æ¨¡å‹è®­ç»ƒå…¨éƒ¨å®Œæˆï¼")
print("=" * 60)
