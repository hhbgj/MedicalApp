"""
è„‘éƒ¨MRIè‚¿ç˜¤æ£€æµ‹æ¨¡å‹è®­ç»ƒ
æ•°æ®é›†ï¼šBrain MRI Images for Brain Tumor Detection
Kaggle: https://www.kaggle.com/datasets/navoneel/brain-mri-images-for-brain-tumor-detection
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
import os

print("=" * 60)
print("ğŸ§  è„‘éƒ¨MRIè‚¿ç˜¤æ£€æµ‹æ¨¡å‹è®­ç»ƒç¨‹åº")
print("=" * 60)

# ========== 1. é…ç½®å‚æ•° ==========
print("\n[1/8] é…ç½®è®­ç»ƒå‚æ•°...")

BASE_DIR = 'C:/MedicalAI'
DATA_DIR = f'{BASE_DIR}/datasets/brain_tumor'
MODEL_DIR = f'{BASE_DIR}/models'
LABELS_DIR = f'{BASE_DIR}/labels'

os.makedirs(MODEL_DIR, exist_ok=True)
os.makedirs(LABELS_DIR, exist_ok=True)

# æ£€æŸ¥æ•°æ®é›†
if not os.path.exists(DATA_DIR):
    print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®é›† {DATA_DIR}")
    print("è¯·ç¡®ä¿å·²ä¸‹è½½å¹¶è§£å‹è„‘è‚¿ç˜¤æ•°æ®é›†åˆ°æŒ‡å®šä½ç½®")
    print("ä¸‹è½½åœ°å€: https://www.kaggle.com/datasets/navoneel/brain-mri-images-for-brain-tumor-detection")
    print("\næ•°æ®é›†ç»“æ„åº”ä¸º:")
    print("  brain_tumor/")
    print("  â”œâ”€â”€ yes/  (æœ‰è‚¿ç˜¤)")
    print("  â””â”€â”€ no/   (æ— è‚¿ç˜¤)")
    exit(1)

# è®­ç»ƒå‚æ•°
IMG_SIZE = 224
BATCH_SIZE = 8  # å¾ˆå°çš„batchå› ä¸ºæ•°æ®é›†å¾ˆå°(253å¼ )
EPOCHS = 40
LEARNING_RATE = 0.0003
MODEL_NAME = 'brain'
CLASS_NAMES = ['NO_TUMOR', 'TUMOR']
CLASS_NAMES_CN = ['æ— è‚¿ç˜¤', 'æœ‰è‚¿ç˜¤']

print(f"  æ•°æ®è·¯å¾„: {DATA_DIR}")
print(f"  å›¾åƒå¤§å°: {IMG_SIZE}x{IMG_SIZE}")
print(f"  æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
print(f"  è®­ç»ƒè½®æ•°: {EPOCHS}")
print(f"  æ¨¡å‹åç§°: {MODEL_NAME}")

# ========== 2. åŠ è½½æ•°æ® ==========
print("\n[2/8] åŠ è½½æ•°æ®...")

# æ•°æ®é›†è¾ƒå°ï¼Œä½¿ç”¨20%éªŒè¯
train_ds = keras.preprocessing.image_dataset_from_directory(
    DATA_DIR,
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    label_mode='binary',
    color_mode='grayscale',  # MRIç°åº¦å›¾
    seed=42,
    validation_split=0.2,
    subset='training'
)

val_ds = keras.preprocessing.image_dataset_from_directory(
    DATA_DIR,
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    label_mode='binary',
    color_mode='grayscale',
    seed=42,
    validation_split=0.2,
    subset='validation'
)

print(f"  ç±»åˆ«: {train_ds.class_names}")
print(f"  è®­ç»ƒæ‰¹æ¬¡: {len(train_ds)}")
print(f"  éªŒè¯æ‰¹æ¬¡: {len(val_ds)}")
print("  âš ï¸ æ³¨æ„: æ•°æ®é›†è¾ƒå°(253å¼ )ï¼Œå·²å¯ç”¨å¼ºæ•°æ®å¢å¼º")

# ========== 3. æ•°æ®é¢„å¤„ç† ==========
print("\n[3/8] é…ç½®æ•°æ®å¤„ç†...")

def preprocess(image, label):
    image = tf.cast(image, tf.float32) / 255.0
    return image, label

def augment(image, label):
    # å¼ºæ•°æ®å¢å¼ºï¼ˆå› ä¸ºæ•°æ®é›†å°ï¼‰
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_flip_up_down(image)
    image = tf.image.random_brightness(image, 0.2)
    image = tf.image.random_contrast(image, 0.8, 1.2)
    
    # éšæœºè£å‰ªå¢å¼º
    padded = tf.image.resize_with_crop_or_pad(image, IMG_SIZE + 30, IMG_SIZE + 30)
    image = tf.image.random_crop(padded, [IMG_SIZE, IMG_SIZE, 1])
    
    return image, label

train_ds = train_ds.map(preprocess).map(augment)
test_ds = val_ds.map(preprocess)

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(200).prefetch(buffer_size=AUTOTUNE)
test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)

print("  âœ“ å¼ºæ•°æ®å¢å¼ºå·²é…ç½®ï¼ˆç¿»è½¬ã€äº®åº¦ã€å¯¹æ¯”åº¦ã€è£å‰ªï¼‰")
print("  âœ“ æ•°æ®ç®¡é“å·²ä¼˜åŒ–")

# ========== 4. æ„å»ºæ¨¡å‹ ==========
print("\n[4/8] æ„å»ºæ¨¡å‹...")

# ä½¿ç”¨MobileNetV2ï¼ˆè½»é‡ä½†æ•ˆæœå¥½ï¼‰
base_model = keras.applications.MobileNetV2(
    input_shape=(IMG_SIZE, IMG_SIZE, 3),
    include_top=False,
    weights='imagenet'
)
base_model.trainable = False

model = keras.Sequential([
    layers.Input(shape=(IMG_SIZE, IMG_SIZE, 1)),
    
    # ç°åº¦è½¬RGB
    layers.Conv2D(3, (1, 1), padding='same'),
    
    # å†…ç½®æ•°æ®å¢å¼º
    layers.RandomRotation(0.15),
    layers.RandomZoom(0.15),
    
    # é¢„è®­ç»ƒæ¨¡å‹
    base_model,
    
    # åˆ†ç±»å¤´ï¼ˆé’ˆå¯¹å°æ•°æ®é›†ä¼˜åŒ–ï¼‰
    layers.GlobalAveragePooling2D(),
    layers.BatchNormalization(),
    layers.Dropout(0.5),  # è¾ƒé«˜dropouté˜²è¿‡æ‹Ÿåˆ
    
    layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.02)),
    layers.BatchNormalization(),
    layers.Dropout(0.5),
    
    layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.02)),
    layers.Dropout(0.3),
    
    layers.Dense(1, activation='sigmoid')
])

print(f"  åŸºç¡€æ¨¡å‹: MobileNetV2")
print(f"  æ¨¡å‹å±‚æ•°: {len(model.layers)}")
print(f"  å¯è®­ç»ƒå‚æ•°: {model.count_params():,}")

# ========== 5. ç¼–è¯‘æ¨¡å‹ ==========
print("\n[5/8] ç¼–è¯‘æ¨¡å‹...")

model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    loss='binary_crossentropy',
    metrics=[
        'accuracy',
        keras.metrics.Precision(name='precision'),
        keras.metrics.Recall(name='recall'),
        keras.metrics.AUC(name='auc')
    ]
)

print("  âœ“ ä¼˜åŒ–å™¨: Adam (lr=0.0003)")
print("  âœ“ æŸå¤±å‡½æ•°: Binary Crossentropy")
print("  âœ“ æ­£åˆ™åŒ–: L2(0.02) + Dropout(0.5)")

# ========== 6. è®­ç»ƒæ¨¡å‹ ==========
print("\n[6/8] å¼€å§‹è®­ç»ƒ...\n")

callbacks = [
    keras.callbacks.EarlyStopping(
        monitor='val_auc',
        patience=10,
        restore_best_weights=True,
        mode='max',
        verbose=1
    ),
    keras.callbacks.ModelCheckpoint(
        f'{MODEL_DIR}/{MODEL_NAME}_best.h5',
        monitor='val_auc',
        save_best_only=True,
        mode='max',
        verbose=1
    ),
    keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=5,
        min_lr=1e-7,
        verbose=1
    )
]

history = model.fit(
    train_ds,
    validation_data=test_ds,
    epochs=EPOCHS,
    callbacks=callbacks,
    verbose=1
)

# ========== 7. è¯„ä¼°å’Œä¿å­˜ ==========
print("\n[7/8] è¯„ä¼°æ¨¡å‹...")

results = model.evaluate(test_ds, verbose=0)

print("\n" + "=" * 60)
print(f"ğŸ§  {MODEL_NAME.upper()} è®­ç»ƒå®Œæˆï¼æœ€ç»ˆæµ‹è¯•ç»“æœ:")
print("=" * 60)
print(f"  æŸå¤±å€¼:   {results[0]:.4f}")
print(f"  å‡†ç¡®ç‡:   {results[1]*100:.2f}%")
print(f"  ç²¾ç¡®ç‡:   {results[2]*100:.2f}%")
print(f"  å¬å›ç‡:   {results[3]*100:.2f}%")
print(f"  AUC:      {results[4]:.4f}")
print("=" * 60)

# ä¿å­˜æ¨¡å‹
model_path = f'{MODEL_DIR}/{MODEL_NAME}_model.h5'
model.save(model_path)
print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜: {model_path}")

# ä¿å­˜æ ‡ç­¾
labels_path = f'{LABELS_DIR}/{MODEL_NAME}_labels.txt'
with open(labels_path, 'w', encoding='utf-8') as f:
    for en, cn in zip(CLASS_NAMES, CLASS_NAMES_CN):
        f.write(f"{en}|{cn}\n")
print(f"âœ… æ ‡ç­¾å·²ä¿å­˜: {labels_path}")

# ========== 8. ç»˜åˆ¶è®­ç»ƒæ›²çº¿ ==========
print("\n[8/8] ç»˜åˆ¶è®­ç»ƒæ›²çº¿...")

plt.style.use('seaborn-v0_8-darkgrid')
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle(f'ğŸ§  {MODEL_NAME.upper()} è„‘è‚¿ç˜¤æ£€æµ‹æ¨¡å‹è®­ç»ƒæ›²çº¿', fontsize=16, fontweight='bold')

axes[0, 0].plot(history.history['accuracy'], 'b-', label='è®­ç»ƒ', linewidth=2)
axes[0, 0].plot(history.history['val_accuracy'], 'r-', label='éªŒè¯', linewidth=2)
axes[0, 0].set_title('å‡†ç¡®ç‡', fontsize=14)
axes[0, 0].set_xlabel('Epoch')
axes[0, 0].set_ylabel('Accuracy')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

axes[0, 1].plot(history.history['loss'], 'b-', label='è®­ç»ƒ', linewidth=2)
axes[0, 1].plot(history.history['val_loss'], 'r-', label='éªŒè¯', linewidth=2)
axes[0, 1].set_title('æŸå¤±å€¼', fontsize=14)
axes[0, 1].set_xlabel('Epoch')
axes[0, 1].set_ylabel('Loss')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

axes[1, 0].plot(history.history['precision'], 'g-', label='è®­ç»ƒ', linewidth=2)
axes[1, 0].plot(history.history['val_precision'], 'orange', label='éªŒè¯', linewidth=2)
axes[1, 0].set_title('ç²¾ç¡®ç‡', fontsize=14)
axes[1, 0].set_xlabel('Epoch')
axes[1, 0].set_ylabel('Precision')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

axes[1, 1].plot(history.history['auc'], 'purple', label='è®­ç»ƒ', linewidth=2)
axes[1, 1].plot(history.history['val_auc'], 'brown', label='éªŒè¯', linewidth=2)
axes[1, 1].set_title('AUC', fontsize=14)
axes[1, 1].set_xlabel('Epoch')
axes[1, 1].set_ylabel('AUC')
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(f'{MODEL_DIR}/{MODEL_NAME}_training.png', dpi=150, bbox_inches='tight')
print(f"âœ… è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {MODEL_NAME}_training.png")

print("\n" + "=" * 60)
print(f"ğŸ‰ {MODEL_NAME.upper()} è„‘è‚¿ç˜¤æ£€æµ‹æ¨¡å‹è®­ç»ƒå…¨éƒ¨å®Œæˆï¼")
print("=" * 60)
